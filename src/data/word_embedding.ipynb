{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcus.joyce\\AppData\\Local\\Temp\\ipykernel_76072\\4204654206.py:12: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_input_file, word2vec_output_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert GloVe file to word2vec file\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "dirname = os.path.abspath('')\n",
    "glove_input_file = os.path.join(dirname, '..', '..', 'data', 'glove.6B.300d.txt')\n",
    "word2vec_output_file = os.path.join(dirname, '..', '..', 'data', 'word2vec.300d.txt')\n",
    "\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the word2vec model\n",
    "\"\"\"\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import os\n",
    "\n",
    "dirname = os.path.abspath('')\n",
    "filename = os.path.join(dirname, '..', '..', 'data', 'word2vec.100d.txt')\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loads file\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dirname = os.path.abspath('')\n",
    "data = os.path.join(dirname, '..', '..', 'data', 'all_data_processed.csv')\n",
    "\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "'''\n",
    "n_datapoints = 100000\n",
    "\n",
    "df = df[:n_datapoints]\n",
    "'''\n",
    "\n",
    "max_sentence_length = 300\n",
    "dimension = 100\n",
    "\n",
    "\n",
    "def vectorize(sentence):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a list of vectors through word embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    out = np.empty((max_sentence_length, dimension))\n",
    "    i_ = 0\n",
    "    for i, word in enumerate(sentence):\n",
    "        if i < max_sentence_length:\n",
    "            try:\n",
    "                out[i] = model[word]\n",
    "            except KeyError:\n",
    "                out[i] = np.zeros(dimension)\n",
    "            i_ += 1\n",
    "    out[range(i_+1, max_sentence_length)] = np.zeros(dimension)  # pad the array with arrays of zeros.\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Take the average of toxicity and severe_toxicity and save file.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "dirname = os.path.abspath('')\n",
    "\n",
    "scores = df[['toxicity', 'severe_toxicity']]\n",
    "\n",
    "scores_np = np.empty(len(scores), dtype='f')\n",
    "\n",
    "for i, row in scores.iterrows():\n",
    "    scores_np[i] = (row[0] + row[1])/2\n",
    "\n",
    "del scores\n",
    "\n",
    "np.save(os.path.join(dirname, '..', '..', 'data', 'y.npy'), scores_np)\n",
    "\n",
    "del scores_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Vectorize every word in the dataset and save file.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "dirname = os.path.abspath('')\n",
    "\n",
    "comments = df['comment_text'].apply(eval)  # The lists in the dataframe are stored as strings and need to be converted to lists.\n",
    "\n",
    "comments_vectorized = np.empty((len(comments), max_sentence_length, dimension), dtype='f')\n",
    "\n",
    "for j, c in enumerate(comments):\n",
    "    comments_vectorized[j] = vectorize(c)\n",
    "\n",
    "del comments\n",
    "\n",
    "np.save(os.path.join(dirname, '..', '..', 'data', 'X.npy'), comments_vectorized)\n",
    "\n",
    "del comments_vectorized\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('gymnasiearbete_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f8f9a1c5dea66502c36bf9832faacb0aadd87eec192002b66fedfa188ddbb25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
