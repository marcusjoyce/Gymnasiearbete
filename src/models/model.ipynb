{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the data and split into training and testing.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "dirname = os.path.abspath('')\n",
    "\n",
    "X = np.load(os.path.join(dirname, '..', '..', 'data', 'X.npy'))\n",
    "y = np.load(os.path.join(dirname, '..', '..', 'data', 'y.npy'))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=576)\n",
    "\n",
    "del X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1047/1047 [==============================] - 367s 349ms/step - loss: 0.3007 - accuracy: 0.9307 - val_loss: 0.2325 - val_accuracy: 0.9327\n",
      "Epoch 2/8\n",
      "1047/1047 [==============================] - 410s 391ms/step - loss: 0.2181 - accuracy: 0.9359 - val_loss: 0.2040 - val_accuracy: 0.9387\n",
      "Epoch 3/8\n",
      "1047/1047 [==============================] - 452s 432ms/step - loss: 0.2041 - accuracy: 0.9406 - val_loss: 0.2062 - val_accuracy: 0.9405\n",
      "Epoch 4/8\n",
      "1047/1047 [==============================] - 442s 422ms/step - loss: 0.2004 - accuracy: 0.9414 - val_loss: 0.2028 - val_accuracy: 0.9399\n",
      "Epoch 5/8\n",
      "1047/1047 [==============================] - 424s 405ms/step - loss: 0.1965 - accuracy: 0.9414 - val_loss: 0.2036 - val_accuracy: 0.9401\n",
      "Epoch 6/8\n",
      "1047/1047 [==============================] - 411s 393ms/step - loss: 0.1987 - accuracy: 0.9419 - val_loss: 0.2074 - val_accuracy: 0.9386\n",
      "Epoch 7/8\n",
      "1047/1047 [==============================] - 401s 383ms/step - loss: 0.2003 - accuracy: 0.9419 - val_loss: 0.1957 - val_accuracy: 0.9411\n",
      "Epoch 8/8\n",
      "1047/1047 [==============================] - 449s 429ms/step - loss: 0.1981 - accuracy: 0.9423 - val_loss: 0.2187 - val_accuracy: 0.9388\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train model\n",
    "\"\"\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout, Activation\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "\n",
    "batch_size = 64\n",
    "maxlen = 300\n",
    "embedding_dims = 100 #Length of the token vectors\n",
    "filters = 128 #number of filters in your Convnet\n",
    "kernel_size = 16 # a window size of 16 tokens\n",
    "epochs = 16\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters, kernel_size, padding='valid', activation='relu', strides=1, input_shape=(maxlen,embedding_dims), kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model.add(Conv1D(filters, 8, padding='valid', activation='relu', strides=1, input_shape=(maxlen,embedding_dims), kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(256, activation='leaky_relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',optimizer = 'adam', metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,batch_size = batch_size,epochs = epochs , validation_data = (X_test,y_test))\n",
    "del X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "stop_words = set(map(lambda x : re.sub(r'[^\\w\\s]+', '', x), stopwords.words('english')))  # Loads nltk stopwords and removes punctuation\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import os\n",
    "\n",
    "dirname = os.path.abspath('')\n",
    "filename = os.path.join(dirname, '..', '..', 'data', 'word2vec.100d.txt')\n",
    "\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
    "\n",
    "def vectorize(sentence):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a list of vectors through word embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    out = np.empty((maxlen, embedding_dims))\n",
    "    i_ = 0\n",
    "    for i, word in enumerate(sentence):\n",
    "        if i < maxlen:\n",
    "            try:\n",
    "                out[i] = word2vec_model[word]\n",
    "            except KeyError:\n",
    "                out[i] = np.zeros(embedding_dims)\n",
    "            i_ += 1\n",
    "    out[range(i_+1, maxlen)] = np.zeros(embedding_dims)  # pad the array with arrays of zeros.\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def convert(sentence):\n",
    "    sentence = re.sub(r'[^\\w\\s]+', '', sentence).lower()\n",
    "\n",
    "    sentence = re.split(r'\\s+', sentence)\n",
    "\n",
    "    sentence = [word for word in sentence if word not in stop_words]\n",
    "\n",
    "    sentence = [wnl.lemmatize(wnl.lemmatize(word), pos='v') for word in sentence]\n",
    "\n",
    "    sentence = vectorize(sentence)\n",
    "\n",
    "    sentence = np.reshape(sentence, (1, maxlen, embedding_dims))\n",
    "    return sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "0.011513927\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The model has some issues and often outputs \"nan\", this will run until it gives an answer\n",
    "a = float('nan')\n",
    "while a != a:\n",
    "    a = model.predict(convert(\"Love you!\"))[0][0]\n",
    "\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('gymnasiearbete_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f8f9a1c5dea66502c36bf9832faacb0aadd87eec192002b66fedfa188ddbb25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
